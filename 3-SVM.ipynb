{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Komentarz:\n",
    "    To możliwe, że Naive Bayes radził sobie lepiej :) \n",
    "        https://stackoverflow.com/questions/35360081/naive-bayes-vs-svm-for-classifying-text-data\n",
    "            \n",
    "Ogólnie - do przemyślenia, może da radę lepiej..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ActionName', 'Capability']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_helpers\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "load_main = True\n",
    "\n",
    "main_cats = ['ActionName', 'Capability']\n",
    "dataframes = {cat : {} for cat in main_cats} if load_main else {}\n",
    "\n",
    "for cat in main_cats:\n",
    "    path = os.getcwd() + \"/\" + cat + \"/Processed/\"\n",
    "    ls = os.listdir(path)\n",
    "    for file in ls:\n",
    "        if (load_main and cat in file) or (not load_main and cat not in file):\n",
    "            df = pd.read_csv(path + file, encoding='utf-8')\n",
    "\n",
    "            df.rename({\"Unnamed: 0\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "            df.drop([\"a\"], axis=1, inplace=True)\n",
    "\n",
    "            df.rename({\"Unnamed: 0.1\":\"a\"}, axis=\"columns\", inplace=True)\n",
    "            df.drop([\"a\"], axis=1, inplace=True)\n",
    "\n",
    "            df_type = file.split('-')[1]\n",
    "            if load_main:\n",
    "                dataframes[cat][df_type] = df\n",
    "            else:\n",
    "                sub_cat = file.split('-')[0]\n",
    "                if sub_cat not in dataframes.keys():\n",
    "                    dataframes[sub_cat] = {}\n",
    "                dataframes[sub_cat][df_type] = df\n",
    "\n",
    "if not load_main:\n",
    "    main_cats = list(dataframes.keys())\n",
    "main_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clf_helpers import do_the_pipeline\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbsvm import NBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ActionName:\n",
      "\n",
      "# RELATIONS\n",
      "Vectorizer: W słowniku znajduje się 16276 różnych słów\n",
      "- Zbiór treningowy:\n",
      "\tACCURACY: 98.3572%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  ActionName       0.96      0.99      0.98      1154\n",
      "NoActionName       1.00      0.98      0.99      2194\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3348\n",
      "   macro avg       0.98      0.99      0.98      3348\n",
      "weighted avg       0.98      0.98      0.98      3348\n",
      "\n",
      "- Zbiór testowy:\n",
      "\tACCURACY: 77.6371%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  ActionName       0.65      0.72      0.69        80\n",
      "NoActionName       0.85      0.80      0.83       157\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       237\n",
      "   macro avg       0.75      0.76      0.76       237\n",
      "weighted avg       0.78      0.78      0.78       237\n",
      "\n",
      "\n",
      ">>> Capability:\n",
      "\n",
      "# RELATIONS\n",
      "Vectorizer: W słowniku znajduje się 16276 różnych słów\n",
      "- Zbiór treningowy:\n",
      "\tACCURACY: 98.1481%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Capability       1.00      0.98      0.99      2817\n",
      "NoCapability       0.90      1.00      0.94       531\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3348\n",
      "   macro avg       0.95      0.99      0.97      3348\n",
      "weighted avg       0.98      0.98      0.98      3348\n",
      "\n",
      "- Zbiór testowy:\n",
      "\tACCURACY: 80.1688%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Capability       0.88      0.87      0.88       190\n",
      "NoCapability       0.50      0.51      0.51        47\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       237\n",
      "   macro avg       0.69      0.69      0.69       237\n",
      "weighted avg       0.80      0.80      0.80       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "    \n",
    "pipeline = Pipeline([      \n",
    "    ('vectorizer',\n",
    "#      TfidfVectorizer(\n",
    "     CountVectorizer(\n",
    "         preprocessor=dummy, \n",
    "         ngram_range=(1, 2),\n",
    "         analyzer='word',\n",
    "         binary=False,\n",
    "#          max_features=2000\n",
    "     )),\n",
    "    ('clf', SVC(\n",
    "        C=100.0, \n",
    "        kernel='rbf',\n",
    "        gamma = 0.001, \n",
    "        class_weight = 'balanced'\n",
    "    )),\n",
    "])\n",
    "\n",
    "do_the_pipeline(pipeline, main_cats, dataframes, accuracy=True, report=True, top_features=False, neigh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for ROC_AUC\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.734 (+/-0.119) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.716 (+/-0.119) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.759 (+/-0.110) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.719 (+/-0.124) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.757 (+/-0.092) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.734 (+/-0.119) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.063) for {'C': 200, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.751 (+/-0.125) for {'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.752 (+/-0.052) for {'C': 300, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.123) for {'C': 300, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.727 (+/-0.022) for {'C': 10, 'kernel': 'linear'}\n",
      "0.707 (+/-0.049) for {'C': 50, 'kernel': 'linear'}\n",
      "0.698 (+/-0.045) for {'C': 100, 'kernel': 'linear'}\n",
      "0.696 (+/-0.041) for {'C': 200, 'kernel': 'linear'}\n",
      "0.697 (+/-0.046) for {'C': 300, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       157\n",
      "           1       0.69      0.56      0.62        80\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       237\n",
      "   macro avg       0.74      0.72      0.73       237\n",
      "weighted avg       0.76      0.77      0.76       237\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for ACCURACY\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.686 (+/-0.054) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.655 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.734 (+/-0.069) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.662 (+/-0.023) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.736 (+/-0.055) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.685 (+/-0.053) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.727 (+/-0.044) for {'C': 200, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.718 (+/-0.062) for {'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.724 (+/-0.044) for {'C': 300, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.725 (+/-0.073) for {'C': 300, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.700 (+/-0.033) for {'C': 10, 'kernel': 'linear'}\n",
      "0.679 (+/-0.046) for {'C': 50, 'kernel': 'linear'}\n",
      "0.672 (+/-0.045) for {'C': 100, 'kernel': 'linear'}\n",
      "0.669 (+/-0.047) for {'C': 200, 'kernel': 'linear'}\n",
      "0.668 (+/-0.047) for {'C': 300, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       157\n",
      "           1       0.68      0.66      0.67        80\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       237\n",
      "   macro avg       0.75      0.75      0.75       237\n",
      "weighted avg       0.78      0.78      0.78       237\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for PRECISION\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jells123/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.655 (+/-0.263) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.000 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.662 (+/-0.125) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.636 (+/-0.450) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.650 (+/-0.094) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.641 (+/-0.264) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.075) for {'C': 200, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.681 (+/-0.143) for {'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.612 (+/-0.069) for {'C': 300, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.666 (+/-0.150) for {'C': 300, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.561 (+/-0.049) for {'C': 10, 'kernel': 'linear'}\n",
      "0.531 (+/-0.059) for {'C': 50, 'kernel': 'linear'}\n",
      "0.522 (+/-0.056) for {'C': 100, 'kernel': 'linear'}\n",
      "0.519 (+/-0.058) for {'C': 200, 'kernel': 'linear'}\n",
      "0.518 (+/-0.057) for {'C': 300, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84       157\n",
      "           1       0.77      0.46      0.58        80\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       237\n",
      "   macro avg       0.77      0.70      0.71       237\n",
      "weighted avg       0.77      0.77      0.75       237\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for RECALL\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.179 (+/-0.128) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.000 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.455 (+/-0.215) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.044 (+/-0.039) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.510 (+/-0.197) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.179 (+/-0.127) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.530 (+/-0.167) for {'C': 200, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.333 (+/-0.171) for {'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.553 (+/-0.150) for {'C': 300, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.392 (+/-0.192) for {'C': 300, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.601 (+/-0.087) for {'C': 10, 'kernel': 'linear'}\n",
      "0.590 (+/-0.092) for {'C': 50, 'kernel': 'linear'}\n",
      "0.589 (+/-0.073) for {'C': 100, 'kernel': 'linear'}\n",
      "0.583 (+/-0.067) for {'C': 200, 'kernel': 'linear'}\n",
      "0.583 (+/-0.065) for {'C': 300, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.78       157\n",
      "           1       0.57      0.70      0.63        80\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       237\n",
      "   macro avg       0.70      0.72      0.70       237\n",
      "weighted avg       0.74      0.72      0.73       237\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Grid Search here, for one of the classes\n",
    "- still not very satisfactory ...\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [\n",
    "    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "        'C': [10, 50, 100, 200, 300]},\n",
    "    {'kernel': ['linear'], 'C': [10, 50, 100, 200, 300]}\n",
    "]\n",
    "\n",
    "scores = ['roc_auc', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                 preprocessor=dummy, \n",
    "                 ngram_range=(1, 1),\n",
    "                 analyzer='word'\n",
    "             )\n",
    "\n",
    "train = dataframes['ActionName']['Train']\n",
    "test = dataframes['ActionName']['Test']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score.upper())\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), parameters, cv=5,\n",
    "#                        scoring='%s_macro' % score\n",
    "                       scoring=score\n",
    "                      )\n",
    "    \n",
    "    pipeline = Pipeline([      \n",
    "        ('vectorizer', vectorizer),\n",
    "        ('clf', clf ),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train['text-rel-tokens'], train['label_num'])\n",
    "    clf = pipeline.named_steps['clf']\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = test['label_num'], pipeline.predict(test['text-rel-tokens'])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> ActionName:\n",
      "\n",
      "# RELATIONS\n",
      "Vectorizer: W słowniku znajduje się 16276 różnych słów\n",
      "- Zbiór treningowy:\n",
      "\tACCURACY: 67.1147%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  ActionName       0.98      0.05      0.09      1154\n",
      "NoActionName       0.67      1.00      0.80      2194\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      3348\n",
      "   macro avg       0.82      0.52      0.44      3348\n",
      "weighted avg       0.77      0.67      0.55      3348\n",
      "\n",
      "- Zbiór testowy:\n",
      "\tACCURACY: 70.4641%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  ActionName       0.86      0.15      0.26        80\n",
      "NoActionName       0.70      0.99      0.82       157\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       237\n",
      "   macro avg       0.78      0.57      0.54       237\n",
      "weighted avg       0.75      0.70      0.63       237\n",
      "\n",
      "\n",
      ">>> Capability:\n",
      "\n",
      "# RELATIONS\n",
      "Vectorizer: W słowniku znajduje się 16276 różnych słów\n",
      "- Zbiór treningowy:\n",
      "\tACCURACY: 88.0227%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Capability       0.96      0.89      0.93      2817\n",
      "NoCapability       0.59      0.82      0.68       531\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      3348\n",
      "   macro avg       0.78      0.85      0.80      3348\n",
      "weighted avg       0.90      0.88      0.89      3348\n",
      "\n",
      "- Zbiór testowy:\n",
      "\tACCURACY: 79.3249%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Capability       0.84      0.92      0.88       190\n",
      "NoCapability       0.47      0.30      0.36        47\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       237\n",
      "   macro avg       0.65      0.61      0.62       237\n",
      "weighted avg       0.77      0.79      0.77       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "    \n",
    "pipeline = Pipeline([      \n",
    "    ('vectorizer',\n",
    "#      TfidfVectorizer(\n",
    "     CountVectorizer(\n",
    "         preprocessor=dummy, \n",
    "         ngram_range=(1, 2),\n",
    "         analyzer='word',\n",
    "         binary=False,\n",
    "#          max_features=2000\n",
    "     )),\n",
    "    ('clf', NBSVM()),\n",
    "])\n",
    "\n",
    "do_the_pipeline(pipeline, main_cats, dataframes, accuracy=True, report=True, top_features=False, neigh=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
